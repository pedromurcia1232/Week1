# Week1
Primer taller Deep Learniing
Objetivo

Analizar cómo cambia la salida de una neurona simple al modificar el valor del bias (b), manteniendo constantes los pesos (w1, w2) y las entradas.
El propósito es comprender de manera intuitiva cómo el bias afecta la activación de la neurona.
Resultados obtenidos

b = -0.5 → La neurona se activa con múltiples combinaciones.

b = -1.0 → Aún se activa cuando solo una entrada es 1.

b = -2.0 → Solo se activa cuando ambas entradas son (1,1).
El valor que más se comporta como una compuerta lógica AND es:
Conclusion
 b = -2.0

Se observa que:

Al hacer el bias más negativo, la neurona se vuelve más estricta.

Al aumentar el bias, la neurona se activa con mayor facilidad.

Esto demuestra que el bias desplaza el umbral de activación y afecta directamente la frontera de decisión del modelo.

